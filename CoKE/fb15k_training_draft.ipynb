{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'dataset': 'fb15k',\n",
    "        'vocab_size' : 16396,\n",
    "        'num_relations': 1345,\n",
    "        \n",
    "        # training hyper-paramters\n",
    "        'batch_size':512,\n",
    "        'learning_rate':5e-4,\n",
    "        'epoch':400,\n",
    "        'soft_label':0.8,\n",
    "        'skip_steps':1000,\n",
    "        'max_seq_len':3,\n",
    "        'hidden_dropout_prob':0.1,\n",
    "        'attention_probs_dropout_prob':0.1,\n",
    "        \n",
    "        # file paths for training and evaluation \n",
    "        'data':\"./data\",\n",
    "        # OUTPUT=\"./output_\"+dataset\n",
    "        'train_file':\"./data/train.coke.txt\",\n",
    "        # VALID_FILE=\"./data/valid.coke.txt\"\n",
    "        # TEST_FILE=\"./data/test.coke.txt\"\n",
    "        'vocab_path':\"./data/vocab.txt\",\n",
    "        'true_triple_path':\"./data/all.txt\",\n",
    "        \n",
    "        # transformer (default) config\n",
    "        'hidden_size':256,\n",
    "        'num_hidden_layers':12,\n",
    "        'num_attention_heads':4,\n",
    "        'max_position_embeddings':40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from bin.utils.args import ArgumentGroup, print_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# class ArgumentGroup(parser, title, des, **kwargs)\n",
    "model_g = ArgumentGroup(parser, \"model\", \"model configuration and paths.\")\n",
    "\n",
    "# ArgumentGroup().add_arg(name, type, default, help)\n",
    "model_g.add_arg(\"hidden_size\",              int, 256,            \"CoKE model config: hidden size, default 256\")\n",
    "model_g.add_arg(\"num_hidden_layers\",        int, 6,              \"CoKE model config: num_hidden_layers, default 6\")\n",
    "model_g.add_arg(\"num_attention_heads\",      int, 4,              \"CoKE model config: num_attention_heads, default 4\")\n",
    "model_g.add_arg(\"vocab_size\",               int, -1,           \"CoKE model config: vocab_size\")\n",
    "model_g.add_arg(\"num_relations\",         int, None,           \"CoKE model config: vocab_size\")\n",
    "model_g.add_arg(\"max_position_embeddings\",  int, 10,             \"CoKE model config: max_position_embeddings\")\n",
    "model_g.add_arg(\"hidden_act\",               str, \"gelu\",         \"CoKE model config: hidden_ac, default gelu\")\n",
    "model_g.add_arg(\"hidden_dropout_prob\",      float, 0.1,          \"CoKE model config: attention_probs_dropout_prob, default 0.1\")\n",
    "model_g.add_arg(\"attention_probs_dropout_prob\", float, 0.1,      \"CoKE model config: attention_probs_dropout_prob, default 0.1\")\n",
    "model_g.add_arg(\"initializer_range\",        int, 0.02,           \"CoKE model config: initializer_range\")\n",
    "model_g.add_arg(\"intermediate_size\",        int, 512,            \"CoKE model config: intermediate_size, default 512\")\n",
    "model_g.add_arg(\"init_checkpoint\",          str,  None,          \"Init checkpoint to resume training from, or for prediction only\")\n",
    "model_g.add_arg(\"init_pretraining_params\",  str,  None,          \"Init pre-training params which preforms fine-tuning from. If the \"\n",
    "                 \"arg 'init_checkpoint' has been set, this argument wouldn't be valid.\")\n",
    "model_g.add_arg(\"checkpoints\",              str,  \"checkpoints\", \"Path to save checkpoints.\")\n",
    "model_g.add_arg(\"weight_sharing\",           bool, True,          \"If set, share weights between word embedding and masked lm.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = ArgumentGroup(parser, \"training\", \"training options.\")\n",
    "\n",
    "train_g.add_arg(\"epoch\",             int,    100,                \"Number of epoches for training.\")\n",
    "train_g.add_arg(\"learning_rate\",     float,  5e-5,               \"Learning rate used to train with warmup.\")\n",
    "train_g.add_arg(\"lr_scheduler\",     str, \"linear_warmup_decay\",  \"scheduler of learning rate.\", \n",
    "                choices=['linear_warmup_decay', 'noam_decay'])\n",
    "train_g.add_arg(\"soft_label\",               float, 0.9,          \"Value of soft labels for loss computation\")\n",
    "train_g.add_arg(\"weight_decay\",      float,  0.01,               \"Weight decay rate for L2 regularizer.\")\n",
    "train_g.add_arg(\"warmup_proportion\", float,  0.1,                \"Proportion of training steps to perform linear learning rate warmup for.\")\n",
    "train_g.add_arg(\"use_ema\",           bool,   True,               \"Whether to use ema.\")\n",
    "train_g.add_arg(\"ema_decay\",         float,  0.9999,             \"Decay rate for expoential moving average.\")\n",
    "train_g.add_arg(\"use_fp16\",          bool,   False,              \"Whether to use fp16 mixed precision training.\")\n",
    "train_g.add_arg(\"loss_scaling\",      float,  1.0,                \"Loss scaling factor for mixed precision training, only valid when use_fp16 is enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_g = ArgumentGroup(parser, \"logging\", \"logging related.\")\n",
    "\n",
    "# log_g.add_arg(\"skip_steps\",          int,    1000,               \"The steps interval to print loss.\")\n",
    "# log_g.add_arg(\"verbose\",             bool,   False,              \"Whether to output verbose log.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g = ArgumentGroup(parser, \"data\", \"Data paths, vocab paths and data processing options\")\n",
    "data_g.add_arg(\"dataset\",                   str,   \"\",    \"dataset name\")\n",
    "data_g.add_arg(\"train_file\",                str,   None,  \"Data for training.\")\n",
    "data_g.add_arg(\"sen_candli_file\",           str,   None,  \"sentence_candicate_list file for path query evaluation. Only used for path query datasets\")\n",
    "data_g.add_arg(\"sen_trivial_file\",           str,   None,  \"trivial sentence file for pathquery evaluation. Only used for path query datasets\")\n",
    "data_g.add_arg(\"predict_file\",              str,   None,  \"Data for predictions.\")\n",
    "data_g.add_arg(\"vocab_path\",                str,   None,  \"Path to vocabulary.\")\n",
    "data_g.add_arg(\"true_triple_path\",          str,   None,  \"Path to all true triples. Only used for KBC evaluation.\")\n",
    "data_g.add_arg(\"max_seq_len\",               int,   3,     \"Number of tokens of the longest sequence.\")\n",
    "data_g.add_arg(\"batch_size\",                int,   12,    \"Total examples' number in batch for training. see also --in_tokens.\")\n",
    "data_g.add_arg(\"in_tokens\",                 bool,  False,\n",
    "               \"If set, the batch size will be the maximum number of tokens in one batch. \"\n",
    "               \"Otherwise, it will be the maximum number of examples in one batch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument --do_train: conflicting option string: --do_train",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f22370b230ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrun_type_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArgumentGroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"run_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"running type options.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_type_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_train\"\u001b[0m\u001b[1;33m,\u001b[0m                     \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;34m\"Whether to perform training.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrun_type_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_predict\"\u001b[0m\u001b[1;33m,\u001b[0m                   \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;34m\"Whether to perform prediction.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrun_type_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"use_cuda\"\u001b[0m\u001b[1;33m,\u001b[0m                     \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;34m\"If set, use GPU for training, default is True.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrun_type_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"use_fast_executor\"\u001b[0m\u001b[1;33m,\u001b[0m            \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;34m\"If set, use fast parallel executor (in experiment).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Workspace\\_RWTH\\_msc_mi\\SoSe 2022\\XAI\\CoKE\\CoKE\\bin\\utils\\args.py\u001b[0m in \u001b[0;36madd_arg\u001b[1;34m(self, name, type, default, help, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr2bool\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         self._group.add_argument(\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[1;34m\"--\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1384\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_argument_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1590\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ArgumentGroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1591\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_group_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1592\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m         \u001b[1;31m# resolve any conflicts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1400\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_conflict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m         \u001b[1;31m# add to actions list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\argparse.py\u001b[0m in \u001b[0;36m_check_conflict\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1538\u001b[0m             \u001b[0mconflict_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1539\u001b[1;33m             \u001b[0mconflict_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1541\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_conflict_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\argparse.py\u001b[0m in \u001b[0;36m_handle_conflict_error\u001b[1;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[0;32m   1546\u001b[0m                                      \u001b[1;32mfor\u001b[0m \u001b[0moption_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m                                      in conflicting_actions])\n\u001b[1;32m-> 1548\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mconflict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_conflict_resolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument --do_train: conflicting option string: --do_train"
     ]
    }
   ],
   "source": [
    "# run_type_g = ArgumentGroup(parser, \"run_type\", \"running type options.\")\n",
    "# run_type_g.add_arg(\"do_train\",                     bool,   False,  \"Whether to perform training.\")\n",
    "# run_type_g.add_arg(\"do_predict\",                   bool,   False,  \"Whether to perform prediction.\")\n",
    "# run_type_g.add_arg(\"use_cuda\",                     bool,   True,   \"If set, use GPU for training, default is True.\")\n",
    "# run_type_g.add_arg(\"use_fast_executor\",            bool,   False,  \"If set, use fast parallel executor (in experiment).\")\n",
    "# run_type_g.add_arg(\"num_iteration_per_drop_scope\", int,    1,      \"Ihe iteration intervals to clean up temporary variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--hidden_size HIDDEN_SIZE] [--num_hidden_layers NUM_HIDDEN_LAYERS]\n",
      "                             [--num_attention_heads NUM_ATTENTION_HEADS] [--vocab_size VOCAB_SIZE]\n",
      "                             [--num_relations NUM_RELATIONS] [--max_position_embeddings MAX_POSITION_EMBEDDINGS]\n",
      "                             [--hidden_act HIDDEN_ACT] [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                             [--attention_probs_dropout_prob ATTENTION_PROBS_DROPOUT_PROB]\n",
      "                             [--initializer_range INITIALIZER_RANGE] [--intermediate_size INTERMEDIATE_SIZE]\n",
      "                             [--init_checkpoint INIT_CHECKPOINT] [--init_pretraining_params INIT_PRETRAINING_PARAMS]\n",
      "                             [--checkpoints CHECKPOINTS] [--weight_sharing WEIGHT_SHARING] [--epoch EPOCH]\n",
      "                             [--learning_rate LEARNING_RATE] [--lr_scheduler {linear_warmup_decay,noam_decay}]\n",
      "                             [--soft_label SOFT_LABEL] [--weight_decay WEIGHT_DECAY]\n",
      "                             [--warmup_proportion WARMUP_PROPORTION] [--use_ema USE_EMA] [--ema_decay EMA_DECAY]\n",
      "                             [--use_fp16 USE_FP16] [--loss_scaling LOSS_SCALING] [--dataset DATASET]\n",
      "                             [--train_file TRAIN_FILE] [--sen_candli_file SEN_CANDLI_FILE]\n",
      "                             [--sen_trivial_file SEN_TRIVIAL_FILE] [--predict_file PREDICT_FILE]\n",
      "                             [--vocab_path VOCAB_PATH] [--true_triple_path TRUE_TRIPLE_PATH]\n",
      "                             [--max_seq_len MAX_SEQ_LEN] [--batch_size BATCH_SIZE] [--in_tokens IN_TOKENS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Srijeet Roy\\AppData\\Roaming\\jupyter\\runtime\\kernel-b2a067c0-f28d-42ab-b5ef-9df244c9a371.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ArgumentGroup' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-07e7d484a6f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_g\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hidden_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'ArgumentGroup' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model_g['hidden_size']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
